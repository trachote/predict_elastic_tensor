# SE(3)-Transformers
This code is from [SE(3)-Transformers: 3D Roto-Translation Equivariant Attention Networks](https://github.com/FabianFuchsML/se3-transformer-public).
The code has been modified to be able to set the number of hidden units of the radial part.
Tuning this hyperparameter leads to a substantial enhancement in the training performance on crystal structures.

Please cite them as
```
@inproceedings{fuchs2020se3transformers,
    title={SE(3)-Transformers: 3D Roto-Translation Equivariant Attention Networks},
    author={Fabian B. Fuchs and Daniel E. Worrall and Volker Fischer and Max Welling},
    year={2020},
    booktitle = {Advances in Neural Information Processing Systems 34 (NeurIPS)},
}
```
